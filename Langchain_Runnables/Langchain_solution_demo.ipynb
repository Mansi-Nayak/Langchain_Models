{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-rp06_hefaqD"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fGSNw7gqlhkj"
      },
      "outputs": [],
      "source": [
        "class Runnable(ABC):\n",
        "\n",
        "  @abstractmethod\n",
        "  def invoke(input_data):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fSuwlRuLlkUE"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class Newllm(Runnable):\n",
        "\n",
        "  def __init__(self):\n",
        "    print('LLM created')\n",
        "\n",
        "  def invoke(self, prompt):\n",
        "    response_list = [\n",
        "        'Delhi is the capital of India',\n",
        "        'IPL is a cricket league',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(response_list)}\n",
        "\n",
        "\n",
        "  def predict(self, prompt):\n",
        "\n",
        "    response_list = [\n",
        "        'Delhi is the capital of India',\n",
        "        'IPL is a cricket league',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(response_list)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8gDmh-L1lyKi"
      },
      "outputs": [],
      "source": [
        "class NewPromptTemplate(Runnable):\n",
        "\n",
        "  def __init__(self, template, input_variables):\n",
        "    self.template = template\n",
        "    self.input_variables = input_variables\n",
        "\n",
        "  def invoke(self, input_dict):\n",
        "    return self.template.format(**input_dict)\n",
        "\n",
        "  def format(self, input_dict):\n",
        "    return self.template.format(**input_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lo_9WFsvl5Fi"
      },
      "outputs": [],
      "source": [
        "class NewStrOutputParser(Runnable):\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def invoke(self, input_data):\n",
        "    return input_data['response']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ueNX-jDTl-uA"
      },
      "outputs": [],
      "source": [
        "class RunnableConnector(Runnable):\n",
        "\n",
        "  def __init__(self, runnable_list):\n",
        "    self.runnable_list = runnable_list\n",
        "\n",
        "  def invoke(self, input_data):\n",
        "\n",
        "    for runnable in self.runnable_list:\n",
        "      input_data = runnable.invoke(input_data)\n",
        "\n",
        "    return input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RAplF2XsmBwm"
      },
      "outputs": [],
      "source": [
        "template = NewPromptTemplate(\n",
        "    template='Write a {length} poem about {topic}',\n",
        "    input_variables=['length', 'topic']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEfY2OvSmF2e",
        "outputId": "0512af0a-6f84-4a80-c1e9-5d1fbf816350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM created\n"
          ]
        }
      ],
      "source": [
        "llm = Newllm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TNLuQ8-smKPL"
      },
      "outputs": [],
      "source": [
        "parser = NewStrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ex35pKlfmODt"
      },
      "outputs": [],
      "source": [
        "chain = RunnableConnector([template, llm, parser])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "afVB7qQVmQaR",
        "outputId": "8349c3bd-5455-49c1-b700-d4775e00c139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'IPL is a cricket league'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({'length':'long', 'topic':'india'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IWPfv58HmS5s"
      },
      "outputs": [],
      "source": [
        "template1 = NewPromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x9WAk1nrmWNH"
      },
      "outputs": [],
      "source": [
        "template2 = NewPromptTemplate(\n",
        "    template='Explain the following joke {response}',\n",
        "    input_variables=['response']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k46P-O0omaNr",
        "outputId": "34732c89-8894-428f-dcca-8416bb34049c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM created\n"
          ]
        }
      ],
      "source": [
        "llm = Newllm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LBFYdfcTmfEw"
      },
      "outputs": [],
      "source": [
        "parser = NewStrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "skoPAeiVminy"
      },
      "outputs": [],
      "source": [
        "chain1 = RunnableConnector([template1, llm])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jAfPxdJomkgR"
      },
      "outputs": [],
      "source": [
        "chain2 = RunnableConnector([template2, llm, parser])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DcQ0Bznsmnmn"
      },
      "outputs": [],
      "source": [
        "final_chain = RunnableConnector([chain1, chain2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xr3j40x2mplV",
        "outputId": "c73b56e8-51c6-42bb-8fa5-3d10beb6e74b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Delhi is the capital of India'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_chain.invoke({'topic':'AI'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5o7Wa-NmyUe"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This script defines a modular and reusable pipeline system for chaining components (like templates, LLMs, and parsers).\n",
        "1. It begins by creating an abstract base class `Runnable`, enforcing that all subclasses implement an `invoke()` method.\n",
        "2. `Newllm` is a mock language model class that randomly returns one of several fixed responses.\n",
        "3. `NewPromptTemplate` formats a template string using variables provided in a dictionary (e.g., for creating prompts).\n",
        "4. `NewStrOutputParser` extracts the 'response' key from the dictionary returned by the LLM.\n",
        "5. `RunnableConnector` takes a list of `Runnable` components and sequentially passes the output of one as the input to the next.\n",
        "6. A basic chain is built: `PromptTemplate → LLM → Parser`, which formats a poem prompt, generates a response, and parses it.\n",
        "7. This chain is invoked with inputs (`length='long'`, `topic='india'`) to simulate generating and parsing a poem.\n",
        "8. Another prompt (`template1`) is used to generate a joke from a topic (e.g., 'AI').\n",
        "9. That response is then passed into `template2`, which prompts for an explanation of the joke.\n",
        "10. A second LLM call is made using the new prompt to \"explain the joke.\"\n",
        "11. Finally, a parser extracts the explanation text from the second LLM's output.\n",
        "12. The entire dual-chain setup is constructed using two `RunnableConnector` instances, chained together.\n",
        "13. `final_chain` encapsulates both chains in sequence: joke generation → explanation → output.\n",
        "14. The system is fully modular — you can plug and compose any number of Runnables to create custom LLM workflows.\n",
        "15. This mirrors the design of modern LLM orchestration libraries like LangChain's `RunnableSequence` or `LCEL`.\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
