{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yeCrSs2macJm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class Newllm:\n",
        "\n",
        "  def __init__(self):\n",
        "    print('LLM created')\n",
        "\n",
        "  def predict(self, prompt):\n",
        "\n",
        "    response_list = [\n",
        "        'Delhi is the capital of India',\n",
        "        'IPL is a cricket league',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(response_list)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WPaRN4AjcHFa"
      },
      "outputs": [],
      "source": [
        "class NewPromptTemplate:\n",
        "\n",
        "  def __init__(self, template, input_variables):\n",
        "    self.template = template\n",
        "    self.input_variables = input_variables\n",
        "\n",
        "  def format(self, input_dict):\n",
        "    return self.template.format(**input_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QIXNEC5jcz-g"
      },
      "outputs": [],
      "source": [
        "template = NewPromptTemplate(\n",
        "    template='Write a {length} poem about {topic}',\n",
        "    input_variables=['length', 'topic']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-7Ig0D5sc_je"
      },
      "outputs": [],
      "source": [
        "prompt = template.format({'length':'short','topic':'india'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8t0edAydD9o",
        "outputId": "ac4bf2c0-7172-41e3-9f7b-d587a42e7f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM created\n"
          ]
        }
      ],
      "source": [
        "llm = Newllm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvmruMdsdI2_",
        "outputId": "1ac4a3bf-ff95-4bb6-e63a-88a87aaf048b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'response': 'IPL is a cricket league'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.predict(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j0wNgITldRYm"
      },
      "outputs": [],
      "source": [
        "class NewLLMChain:\n",
        "\n",
        "  def __init__(self, llm, prompt):\n",
        "    self.llm = llm\n",
        "    self.prompt = prompt\n",
        "\n",
        "  def run(self, input_dict):\n",
        "\n",
        "    final_prompt = self.prompt.format(input_dict)\n",
        "    result = self.llm.predict(final_prompt)\n",
        "\n",
        "    return result['response']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "odz9FPdRdgE9"
      },
      "outputs": [],
      "source": [
        "template = NewPromptTemplate(\n",
        "    template='Write a {length} poem about {topic}',\n",
        "    input_variables=['length', 'topic']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vna3gYicdkam",
        "outputId": "66c3e52b-6f05-411d-c8ef-b0be97684291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM created\n"
          ]
        }
      ],
      "source": [
        "llm = Newllm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IQmpm9txdo1O"
      },
      "outputs": [],
      "source": [
        "chain = NewLLMChain(llm, template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iSb8M-1Fd0K0",
        "outputId": "ef984f42-f232-49e5-f46c-d4ac3809c024"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IPL is a cricket league'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run({'length':'short', 'topic': 'india'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m8ic3TmxeD9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nThis script simulates a minimal version of a language model (LLM) pipeline using custom classes.\\n1. A class `Newllm` is defined to represent a simple mock language model.\\n2. When instantiated, `Newllm` prints a confirmation message and exposes a `predict` method.\\n3. The `predict` method takes a prompt string and returns a random predefined response.\\n4. Another class `NewPromptTemplate` handles templated prompt creation with placeholders.\\n5. The `format` method takes a dictionary of variables and fills the template accordingly.\\n6. An instance of `NewPromptTemplate` is created with a poem-generating template using `{length}` and `{topic}`.\\n7. The template is formatted with values `\\'short\\'` and `\\'india\\'`, producing a prompt.\\n8. The `Newllm` model is instantiated, printing \"LLM created\".\\n9. A sample `predict()` call is made on the prompt to simulate a response.\\n10. A higher-level `NewLLMChain` class is then defined to connect the prompt template and LLM.\\n11. The `run()` method takes user input, formats the final prompt, and passes it to the model.\\n12. The model then returns one of the predefined responses based on a random choice.\\n13. A new `NewPromptTemplate` and `Newllm` are instantiated again for the chain demo.\\n14. The `NewLLMChain` object is created by passing both the model and prompt template.\\n15. The chain is executed with user input to return a simulated response based on the formatted prompt.\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "This script simulates a minimal version of a language model (LLM) pipeline using custom classes.\n",
        "1. A class `Newllm` is defined to represent a simple mock language model.\n",
        "2. When instantiated, `Newllm` prints a confirmation message and exposes a `predict` method.\n",
        "3. The `predict` method takes a prompt string and returns a random predefined response.\n",
        "4. Another class `NewPromptTemplate` handles templated prompt creation with placeholders.\n",
        "5. The `format` method takes a dictionary of variables and fills the template accordingly.\n",
        "6. An instance of `NewPromptTemplate` is created with a poem-generating template using `{length}` and `{topic}`.\n",
        "7. The template is formatted with values `'short'` and `'india'`, producing a prompt.\n",
        "8. The `Newllm` model is instantiated, printing \"LLM created\".\n",
        "9. A sample `predict()` call is made on the prompt to simulate a response.\n",
        "10. A higher-level `NewLLMChain` class is then defined to connect the prompt template and LLM.\n",
        "11. The `run()` method takes user input, formats the final prompt, and passes it to the model.\n",
        "12. The model then returns one of the predefined responses based on a random choice.\n",
        "13. A new `NewPromptTemplate` and `Newllm` are instantiated again for the chain demo.\n",
        "14. The `NewLLMChain` object is created by passing both the model and prompt template.\n",
        "15. The chain is executed with user input to return a simulated response based on the formatted prompt.\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
